{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c656815b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np \n",
    "# import tensorflow as tf \n",
    "# from absl import logging\n",
    "# from itertools import repeat\n",
    "# from PIL import Image\n",
    "# from tensorflow.keras import Model\n",
    "# from tensorflow.keras.layers import Add, Concatenate, Lambda\n",
    "# from tensorflow.keras.layers import Conv2D, Input, LeakyReLU\n",
    "# from tensorflow.keras.layers import MaxPool2D, UpSampling2D, ZeroPadding2D\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "# from tensorflow.keras.losses import binary_crossentropy\n",
    "# from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "# yolo_iou_threshold = 0.6 \n",
    "# yolo_score_threshold = 0.6 # Score threshold.\n",
    "# weightyolov3 = '../weights/yolov3.weights' # Path to the file with weights.\n",
    "# size = 416 # Image size.\n",
    "# checkpoints = '../checkpoints/yolov3.tf' # Path to the checkpoint file.\n",
    "# num_classes = 80 # The number of classes in the model.\n",
    "# YOLO_V3_LAYERS = [\n",
    "#     'yolo_darknet',\n",
    "#     'yolo_conv_0',\n",
    "#     'yolo_output_0',\n",
    "#     'yolo_conv_1',\n",
    "#     'yolo_output_1',\n",
    "#     'yolo_conv_2',\n",
    "#     'yolo_output_2'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf33f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to load the weights of the trained model.\n",
    "# def load_darknet_weights(model, weights_file):\n",
    "#     wf = open(weights_file, 'rb')\n",
    "#     layers = YOLO_V3_LAYERS\n",
    "#     for lay_name in layers:\n",
    "#         s_model = model.get_layer(lay_name)\n",
    "#     for i, layer in enumerate(s_model.layers):\n",
    "#         if not layer.name.startswith('conv2d'):\n",
    "#             continue\n",
    "#             batch_n = None\n",
    "#         if i + 1 < len(s_model.layers) and s_model.layers[i + 1].name.startswith('batch_n'):\n",
    "#             batch_n = s_model.layers[i + 1]\n",
    "#             logging.info(\"{}/{} {}\".format(s_model.name, layer.name, 'bn' if batch_n else 'bias'))\n",
    "#             ft = layer.filters\n",
    "#             size = layer.kernel_size[0]\n",
    "#             in_dim = layer.input_shape[-1]\n",
    "#         if batch_n is None:\n",
    "#                 conv_bias = np.fromfile(wf, dtype=np.float32, count=ft)\n",
    "#         else:\n",
    "#             bn_weight = np.fromfile(wf, dtype=np.float32, count=4*ft)\n",
    "#             bn_weight = bn_weight.reshape((4, ft))[[1, 0, 2, 3]]\n",
    "#             c_shape = (ft, in_dim, size, size)\n",
    "#             c_weights = np.fromfile(wf, dtype=np.float32, count=np.product(c_shape))\n",
    "#             c_weights = c_weights.reshape(c_shape).transpose([2, 3, 1, 0])\n",
    "#         if batch_n is None:\n",
    "#                 layer.set_weights([c_weights, c_bias])\n",
    "#         else:\n",
    "#                 layer.set_weights([c_weights])\n",
    "#                 batch_n.set_weights(bn_weight)\n",
    "#         assert len(wf.read()) == 0, 'declined!!'\n",
    "#         wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "894619cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function for calculating IoU.\n",
    "# def interval_overlap(int_1, int_2):\n",
    "#     y1, y2 = int_1\n",
    "#     y3, y4 = int_2\n",
    "#     if y3 < y1:\n",
    "#         return 0 if y4 < y1 else (min(y2,y4) - y1)\n",
    "#     else:\n",
    "#         return 0 if y2 < y3 else (min(y2,y4) - y3)\n",
    "# def intersectionOverUnion(b1, b2):\n",
    "#     inter_w = int_overlap([b1.xmin, b1.xmax], [b2.xmin, b2.xmax])\n",
    "#     inter_h = int_overlap([b1.ymin, b1.ymax], [b2.ymin, b2.ymax])\n",
    "#     inter_area = inter_w * inter_h\n",
    "#     w1, h1 = b1.xmax-b1.xmin, b1.ymax-b1.ymin\n",
    "#     w2, h2 = b2.xmax-b2.xmin, b2.ymax-b2.ymin\n",
    "#     union_area = w1*h1 + w2*h2 - inter_area\n",
    "#     return float(inter_area) / union_area\n",
    "# class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
    "#     def call(self, x, train=False):\n",
    "#         if train is None: train = tf.constant(False)\n",
    "#         train = tf.logical_and(train, self.trainable)\n",
    "#         return super().call(x, train)\n",
    "#     # Define 3 anchor boxes for each cell.   \n",
    "# y_anch = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),(57, 117), (114, 86), (154, 194), (373, 323)], np.float32) / 416\n",
    "# y_anchor_mask = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ddf2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function for drawing bounding boxes.\n",
    "# def draw_outputs(img, op, c_name, white_list=None):\n",
    "#     box, score, label, nums = op\n",
    "#     box, score, label, nums = box[0], score[0], label[0], nums[0]\n",
    "#     wh = np.flip(img.shape[0:2])\n",
    "#     for i in range(nums):\n",
    "#         if c_name[int(classes[i])] not in white_list:\n",
    "#             continue\n",
    "#             x_1y_1 = tuple((np.array(box[i][0:2]) * wh).astype(np.int32))\n",
    "#             x_2y_2 = tuple((np.array(box[i][2:4]) * wh).astype(np.int32))\n",
    "#             ig = cv2.rectangle(ig, x_1y_1, x_2y_2, (255, 0, 0), 2)\n",
    "#             ig = cv2.putText(img, '{} {:.4f}'.format(\n",
    "#                 c_name[int(classes[i])], score[i]),\n",
    "#                 x_1y_1, cv2.FONT_HERS_COMP_SMALL, 1, (0, 0, 255), 2)\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "981820e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DarkConv(x, ft, size, stride=1, batch_n=True):\n",
    "#     if stride == 1:\n",
    "#             padding = 'same'\n",
    "#     else:\n",
    "#             x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
    "#             padding = 'valid'\n",
    "#             x = Conv2D(ft,size,stride,padding,not batch_n,l2(0.0005))(x)\n",
    "#     if batch_n:\n",
    "#             x = BatchNormalization()(x)\n",
    "#             x = LeakyReLU(alpha=0.1)(x)\n",
    "#     return x\n",
    "\n",
    "# def DarknetResidual(x, ft):\n",
    "#     prev = x\n",
    "#     x = DarkConv(x, ft // 2, 1)\n",
    "#     x = DarkConv(x, ft, 3)\n",
    "#     x = Add()([prev , x])\n",
    "#     return x\n",
    "\n",
    "# def DarkBlock(x, ft, block):\n",
    "#     x = DarkConv(x, ft, 3, stride=2)\n",
    "#     for _ in repeat(None, block):\n",
    "#         x = DarknetResidual(x, ft)\n",
    "#     return x\n",
    "\n",
    "# def Darknet(name=None):\n",
    "#     y = inputs = Input([None, None, 3])\n",
    "#     y = DarkConv(y, 32, 3)\n",
    "#     y = DarkBlock(y, 64, 1)\n",
    "#     y = DarkBlock(y, 128, 2)\n",
    "#     y = x_36 = DarknetBlock(y, 256, 8)\n",
    "#     y = x_61 = DarknetBlock(y, 512, 8)\n",
    "#     y = DarkBlock(y, 1024, 4)\n",
    "#     return tf.keras.Model(inputs, (x_36, x_61, x), name=name)\n",
    "\n",
    "# def YoloConv(ft, name=None):\n",
    "#     def yolo_conv(x_in):\n",
    "#         if isinstance(x_in, tuple):\n",
    "#             inp = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "#             x, x_skip = inp\n",
    "#             x = DarkConv(x, filters, 1)\n",
    "#             x = UpSampling2D(2)(x)\n",
    "#             x = Concatenate()([x, x_skip])\n",
    "#         else:\n",
    "#             x = Input(x_in.shape[1:])\n",
    "#             x = DarkConv(x, filters, 1)\n",
    "#             x = DarkConv(x, filters * 2, 3)\n",
    "#             x = DarkConv(x, filters, 1)\n",
    "#             x = DarkConv(x, filters * 2, 3)\n",
    "#             x = DarkConv(x, filters, 1)\n",
    "#         return Model(inputs, x, name=name)(x_in)\n",
    "#     return yolo_conv\n",
    "\n",
    "# def YoloOutput(ft, anch, label, name=None):\n",
    "#     def yolo_op(x_in):\n",
    "#         x = inp = Input(x_in.shape[1:])\n",
    "#         x = DarkConv(x, ft * 2, 3)\n",
    "#         x = DarkConv(x, anch * (label + 5), 1, batch_n=False)\n",
    "#         return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "#     return yolo_op\n",
    "\n",
    "# def yolo_boxes(pred, anch, label):\n",
    "#     g_size = tf.shape(pred)[1]\n",
    "#     b_xy, b_wh, score, c_prob = tf.split(pred, (2, 2, 1, label), axis=-1)\n",
    "#     b_xy = tf.sigmoid(b_xy)\n",
    "#     sc = tf.sigmoid(sc)\n",
    "#     c_prob = tf.sigmoid(c_prob)\n",
    "#     pred_box = tf.concat((b_xy, b_wh), axis=-1)\n",
    "#     gr = tf.meshgrid(tf.range(g_size), tf.range(g_size))\n",
    "#     gr = tf.expand_dims(tf.stack(gr, axis=-1), axis=2)\n",
    "#     b_xy = (b_xy + tf.cast(gr, tf.float32)) /  tf.cast(g_size, tf.float32)\n",
    "#     b_wh = tf.exp(box_wh) * anch\n",
    "#     b_x1y1 = b_xy - b_wh / 2\n",
    "#     b_x2y2 = b_xy + b_wh / 2\n",
    "#     bbox = tf.concat([b_x1y1, b_x2y2], axis=-1)\n",
    "#     return bbox, score, c_prob, pred_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca1c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nonMaximumSuppression(op, anch, mask, label):\n",
    "#     boxes, conf, o_type = [], [], []\n",
    "#     for output in op:\n",
    "#         boxes.append(tf.reshape(op[0], (tf.shape(op[0])[0], -1, tf.shape(op[0])[-1])))\n",
    "#         conf.append(tf.reshape(output[1], (tf.shape(op[1])[0], -1, tf.shape(op[1])[-1])))\n",
    "#         o_type.append(tf.reshape(op[2], (tf.shape(op[2])[0], -1, tf.shape(op[2])[-1])))\n",
    "#     bbox = tf.concat(boxes, axis=1)\n",
    "#     confidence = tf.concat(conf, axis=1)\n",
    "#     c_prob = tf.concat(o_type, axis=1)\n",
    "#     scores = confidence * c_prob\n",
    "#     boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "#         boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "#         scores=tf.reshape(\n",
    "#             scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "#         max_output_size_per_class=100,\n",
    "#         max_total_size=100,\n",
    "#         iou_threshold=yolo_iou_threshold,\n",
    "#         score_threshold=yolo_score_threshold)\n",
    "#     return boxes, scores, classes, valid_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb3791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def YoloV3(size=None, chan=3, anchors=y_anch,masks=y_anchor_mask, classes=80, training=False):\n",
    "#     x = inputs = Input([size, size, chan])\n",
    "#     x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "#     x = YoloConv(512, name='yolo_conv_0')(x)\n",
    "#     output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "#     x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "#     output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "#     x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "#     output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
    "#     if training:\n",
    "#         return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n",
    "#     return Model(inputs, outputs, name='yolov3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b435c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
    "#     def yolo_loss(y_true, y_pred):\n",
    "#         pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(\n",
    "#             y_pred, anchors, classes)\n",
    "#         pred_xy = pred_xywh[..., 0:2]\n",
    "#         pred_wh = pred_xywh[..., 2:4]\n",
    "#         t_box, true_obj, true_class_idx = tf.split(\n",
    "#             y_true, (4, 1, 1), axis=-1)\n",
    "#         tr_xy = (t_box[..., 0:2] + t_box[..., 2:4]) / 2\n",
    "#         t_wh = t_box[..., 2:4] - t_box[..., 0:2]\n",
    "#         b_loss = 2 - t_wh[..., 0] * t_wh[..., 1]\n",
    "#         g_size = tf.shape(y_true)[1]\n",
    "#         grid = tf.meshgrid(tf.range(g_size), tf.range(g_size))\n",
    "#         grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "#         tr_xy = tr_xy * tf.cast(g_size, tf.float32) - tf.cast(grid, tf.float32)\n",
    "#         t_wh = tf.math.log(t_wh / anchors)\n",
    "#         t_wh = tf.where(tf.math.is_inf(t_wh),\n",
    "#                       tf.zeros_like(t_wh), t_wh)\n",
    "#         obj_mask = tf.squeeze(true_obj, -1)\n",
    "#         t_box_flat = tf.boolean_mask(t_box, tf.cast(obj_mask, tf.bool))\n",
    "#         best_iou = tf.reduce_max(intersectionOverUnion(\n",
    "#             pred_box, true_box_flat), axis=-1)\n",
    "#         ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "#         xy_loss = obj_mask * b_loss * tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "#         wh_loss = obj_mask * b_loss * tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "#         o_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "#         o_loss = obj_mask * o_loss + (1 - obj_mask) * ignore_mask * o_loss\n",
    "#         class_loss = obj_mask * sparse_categorical_crossentropy(\n",
    "#             true_class_idx, pred_class)\n",
    "#         xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "#         wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "#         o_loss = tf.reduce_sum(o_loss, axis=(1, 2, 3))\n",
    "#         class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "#         return xy_loss + wh_loss + o_loss + class_loss\n",
    "#     return yolo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29b02b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_targets_for_output(y_true, grid_size, anchor_idxs, classes):\n",
    "#     N = tf.shape(y_true)[0]\n",
    "#     y_true_out = tf.zeros(\n",
    "#       (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\n",
    "#     anchor_idxs = tf.cast(anchor_idxs, tf.int32)\n",
    "#     indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "#     updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "#     idx = 0\n",
    "#     for i in tf.range(N):\n",
    "#         for j in tf.range(tf.shape(y_true)[1]):\n",
    "#             if tf.equal(y_true[i][j][2], 0):\n",
    "#                 continue\n",
    "#             anchor_eq = tf.equal(\n",
    "#                 anchor_idxs, tf.cast(y_true[i][j][5], tf.int32))\n",
    "#             if tf.reduce_any(anchor_eq):\n",
    "#                 box = y_true[i][j][0:4]\n",
    "#                 anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n",
    "#                 grid_xy = tf.cast(b_x_y // (1/grid_size), tf.int32)\n",
    "#                 indexes = indexes.write(\n",
    "#                     idxes, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\n",
    "#                 idxes += 1\n",
    "#             return tf.tensor_scatter_nd_update(\n",
    "#         y_true_out, indexes.stack(), updates.stack())\n",
    "# def transform_targets(y_train, anchors, anchor_masks, classes):\n",
    "#     outputs = []\n",
    "#     grid_size = 13\n",
    "#     anchors = tf.cast(anchors, tf.float32)\n",
    "#     a_area = anchors[..., 0] * anchors[..., 1]\n",
    "#     b_wh = y_train[..., 2:4] - y_train[..., 0:2]\n",
    "#     b_wh = tf.tile(tf.expand_dims(box_wh, -2),\n",
    "#                     (1, 1, tf.shape(anchors)[0], 1))\n",
    "#     b_area = b_wh[..., 0] * box_wh[..., 1]\n",
    "#     inters = tf.minimum(b_wh[..., 0], anchors[..., 0]) * tf.minimum(b_wh[..., 1], anchors[..., 1])\n",
    "#     iou = inters / (box_area + a_area - inters)\n",
    "#     anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n",
    "#     anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\n",
    "#     y_train = tf.concat([y_train, anchor_idx], axis=-1)\n",
    "#     for anchor_idxs in anchor_masks:\n",
    "#         outputs.append(transform_targets_for_output(\n",
    "#             y_train, grid_size, anchor_idxs, classes))\n",
    "#         grid_size *= 2\n",
    "#         return tuple(outputs) \n",
    "    \n",
    "# def preprocess_image(x_train, size):\n",
    "#     return (tf.image.resize(x_train, (size, size))) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1edf1e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo = YoloV3(classes=num_classes)\n",
    "# load_darknet_weights(yolo, weightyolov3)\n",
    "# yolo.save_weights(checkpoints)\n",
    "# def detect_objects(img_path, white_list=None):\n",
    "#     image = img_path     \n",
    "#     img = tf.image.decode_image(open(image, 'rb').read(), channels=3)\n",
    "#     img = tf.expand_dims(img, 0)\n",
    "#     img = preprocess_image(img, size)\n",
    "#     bx, scor, label, num = yolo(img)\n",
    "#     img = cv2.imread(image)\n",
    "#     img = draw_outputs(img, (bx, scor, label, num), class_names, white_list)\n",
    "#     cv2.imwrite('detected_{:}'.format(img_path), img)\n",
    "#     detected = Image.open('detected_{:}'.format(img_path))\n",
    "#     detected.show()\n",
    "# detect_objects('test.jpg', ['bear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dcfd739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    " \n",
    "def _conv_block(inp, convs, skip=True):\n",
    "\tx = inp\n",
    "\tcount = 0\n",
    "\tfor conv in convs:\n",
    "\t\tif count == (len(convs) - 2) and skip:\n",
    "\t\t\tskip_connection = x\n",
    "\t\tcount += 1\n",
    "\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
    "\t\tx = Conv2D(conv['filter'],\n",
    "\t\t\t\t   conv['kernel'],\n",
    "\t\t\t\t   strides=conv['stride'],\n",
    "\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n",
    "\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n",
    "\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "\treturn add([skip_connection, x]) if skip else x\n",
    " \n",
    "def make_yolov3_model():\n",
    "\tinput_image = Input(shape=(None, None, 3))\n",
    "\t# Layer  0 => 4\n",
    "\tx = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "\t# Layer  5 => 8\n",
    "\tx = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "\t# Layer  9 => 11\n",
    "\tx = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "\t# Layer 12 => 15\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "\t# Layer 16 => 36\n",
    "\tfor i in range(7):\n",
    "\t\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "\tskip_36 = x\n",
    "\t# Layer 37 => 40\n",
    "\tx = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "\t# Layer 41 => 61\n",
    "\tfor i in range(7):\n",
    "\t\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "\tskip_61 = x\n",
    "\t# Layer 62 => 65\n",
    "\tx = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "\t# Layer 66 => 74\n",
    "\tfor i in range(3):\n",
    "\t\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "\t# Layer 75 => 79\n",
    "\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "\t# Layer 80 => 82\n",
    "\tyolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "\t\t\t\t\t\t\t  {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
    "\t# Layer 83 => 86\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "\tx = UpSampling2D(2)(x)\n",
    "\tx = concatenate([x, skip_61])\n",
    "\t# Layer 87 => 91\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "\t# Layer 92 => 94\n",
    "\tyolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "\t\t\t\t\t\t\t  {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
    "\t# Layer 95 => 98\n",
    "\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "\tx = UpSampling2D(2)(x)\n",
    "\tx = concatenate([x, skip_36])\n",
    "\t# Layer 99 => 106\n",
    "\tyolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "\t\t\t\t\t\t\t   {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
    "\tmodel = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
    "\treturn model\n",
    " \n",
    "class WeightReader:\n",
    "\tdef __init__(self, weight_file):\n",
    "\t\twith open(weight_file, 'rb') as w_f:\n",
    "\t\t\tmajor,\t= struct.unpack('i', w_f.read(4))\n",
    "\t\t\tminor,\t= struct.unpack('i', w_f.read(4))\n",
    "\t\t\trevision, = struct.unpack('i', w_f.read(4))\n",
    "\t\t\tif (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "\t\t\t\tw_f.read(8)\n",
    "\t\t\telse:\n",
    "\t\t\t\tw_f.read(4)\n",
    "\t\t\ttranspose = (major > 1000) or (minor > 1000)\n",
    "\t\t\tbinary = w_f.read()\n",
    "\t\tself.offset = 0\n",
    "\t\tself.all_weights = np.frombuffer(binary, dtype='float32')\n",
    " \n",
    "\tdef read_bytes(self, size):\n",
    "\t\tself.offset = self.offset + size\n",
    "\t\treturn self.all_weights[self.offset-size:self.offset]\n",
    " \n",
    "\tdef load_weights(self, model):\n",
    "\t\tfor i in range(106):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tconv_layer = model.get_layer('conv_' + str(i))\n",
    "\t\t\t\tprint(\"loading weights of convolution #\" + str(i))\n",
    "\t\t\t\tif i not in [81, 93, 105]:\n",
    "\t\t\t\t\tnorm_layer = model.get_layer('bnorm_' + str(i))\n",
    "\t\t\t\t\tsize = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\t\t\t\t\tbeta  = self.read_bytes(size) # bias\n",
    "\t\t\t\t\tgamma = self.read_bytes(size) # scale\n",
    "\t\t\t\t\tmean  = self.read_bytes(size) # mean\n",
    "\t\t\t\t\tvar   = self.read_bytes(size) # variance\n",
    "\t\t\t\t\tweights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "\t\t\t\tif len(conv_layer.get_weights()) > 1:\n",
    "\t\t\t\t\tbias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
    "\t\t\t\t\tconv_layer.set_weights([kernel, bias])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
    "\t\t\t\t\tconv_layer.set_weights([kernel])\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\tprint(\"no convolution #\" + str(i))\n",
    " \n",
    "\tdef reset(self):\n",
    "\t\tself.offset = 0\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93fda236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights of convolution #0\n",
      "loading weights of convolution #1\n",
      "loading weights of convolution #2\n",
      "loading weights of convolution #3\n",
      "no convolution #4\n",
      "loading weights of convolution #5\n",
      "loading weights of convolution #6\n",
      "loading weights of convolution #7\n",
      "no convolution #8\n",
      "loading weights of convolution #9\n",
      "loading weights of convolution #10\n",
      "no convolution #11\n",
      "loading weights of convolution #12\n",
      "loading weights of convolution #13\n",
      "loading weights of convolution #14\n",
      "no convolution #15\n",
      "loading weights of convolution #16\n",
      "loading weights of convolution #17\n",
      "no convolution #18\n",
      "loading weights of convolution #19\n",
      "loading weights of convolution #20\n",
      "no convolution #21\n",
      "loading weights of convolution #22\n",
      "loading weights of convolution #23\n",
      "no convolution #24\n",
      "loading weights of convolution #25\n",
      "loading weights of convolution #26\n",
      "no convolution #27\n",
      "loading weights of convolution #28\n",
      "loading weights of convolution #29\n",
      "no convolution #30\n",
      "loading weights of convolution #31\n",
      "loading weights of convolution #32\n",
      "no convolution #33\n",
      "loading weights of convolution #34\n",
      "loading weights of convolution #35\n",
      "no convolution #36\n",
      "loading weights of convolution #37\n",
      "loading weights of convolution #38\n",
      "loading weights of convolution #39\n",
      "no convolution #40\n",
      "loading weights of convolution #41\n",
      "loading weights of convolution #42\n",
      "no convolution #43\n",
      "loading weights of convolution #44\n",
      "loading weights of convolution #45\n",
      "no convolution #46\n",
      "loading weights of convolution #47\n",
      "loading weights of convolution #48\n",
      "no convolution #49\n",
      "loading weights of convolution #50\n",
      "loading weights of convolution #51\n",
      "no convolution #52\n",
      "loading weights of convolution #53\n",
      "loading weights of convolution #54\n",
      "no convolution #55\n",
      "loading weights of convolution #56\n",
      "loading weights of convolution #57\n",
      "no convolution #58\n",
      "loading weights of convolution #59\n",
      "loading weights of convolution #60\n",
      "no convolution #61\n",
      "loading weights of convolution #62\n",
      "loading weights of convolution #63\n",
      "loading weights of convolution #64\n",
      "no convolution #65\n",
      "loading weights of convolution #66\n",
      "loading weights of convolution #67\n",
      "no convolution #68\n",
      "loading weights of convolution #69\n",
      "loading weights of convolution #70\n",
      "no convolution #71\n",
      "loading weights of convolution #72\n",
      "loading weights of convolution #73\n",
      "no convolution #74\n",
      "loading weights of convolution #75\n",
      "loading weights of convolution #76\n",
      "loading weights of convolution #77\n",
      "loading weights of convolution #78\n",
      "loading weights of convolution #79\n",
      "loading weights of convolution #80\n",
      "loading weights of convolution #81\n",
      "no convolution #82\n",
      "no convolution #83\n",
      "loading weights of convolution #84\n",
      "no convolution #85\n",
      "no convolution #86\n",
      "loading weights of convolution #87\n",
      "loading weights of convolution #88\n",
      "loading weights of convolution #89\n",
      "loading weights of convolution #90\n",
      "loading weights of convolution #91\n",
      "loading weights of convolution #92\n",
      "loading weights of convolution #93\n",
      "no convolution #94\n",
      "no convolution #95\n",
      "loading weights of convolution #96\n",
      "no convolution #97\n",
      "no convolution #98\n",
      "loading weights of convolution #99\n",
      "loading weights of convolution #100\n",
      "loading weights of convolution #101\n",
      "loading weights of convolution #102\n",
      "loading weights of convolution #103\n",
      "loading weights of convolution #104\n",
      "loading weights of convolution #105\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\anaconda3\\envs\\Birds\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model = make_yolov3_model()\n",
    "# load the model weights\n",
    "weight_reader = WeightReader('../weights/yolov3 .weights')\n",
    "# set the model weights into the model\n",
    "weight_reader.load_weights(model)\n",
    "# save the model to file\n",
    "model.save('../models/yoloV3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c820047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x00000184E7E2EDB0>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnidentifiedImageError\u001B[0m                    Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2164/3525386249.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    175\u001B[0m \u001B[0mphoto_filename\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'../data/Appelvink_Man/Appelvink_Man_0.mp4'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    176\u001B[0m \u001B[1;31m# load and prepare image\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 177\u001B[1;33m \u001B[0mimage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimage_w\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimage_h\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_image_pixels\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mphoto_filename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0minput_w\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_h\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    178\u001B[0m \u001B[1;31m# make prediction\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[0myhat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2164/3525386249.py\u001B[0m in \u001B[0;36mload_image_pixels\u001B[1;34m(filename, shape)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mload_image_pixels\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m         \u001B[1;31m# load the image to get its shape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 117\u001B[1;33m         \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_img\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    118\u001B[0m         \u001B[0mwidth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheight\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m         \u001B[1;31m# load the image with the required size\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Birds\\lib\\site-packages\\keras\\preprocessing\\image.py\u001B[0m in \u001B[0;36mload_img\u001B[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001B[0m\n\u001B[0;32m    311\u001B[0m       \u001B[0mValueError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0minterpolation\u001B[0m \u001B[0mmethod\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0msupported\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    312\u001B[0m   \"\"\"\n\u001B[1;32m--> 313\u001B[1;33m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001B[0m\u001B[0;32m    314\u001B[0m                         target_size=target_size, interpolation=interpolation)\n\u001B[0;32m    315\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_preprocessing\\image\\utils.py\u001B[0m in \u001B[0;36mload_img\u001B[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001B[0m\n\u001B[0;32m    112\u001B[0m                           'The use of `load_img` requires PIL.')\n\u001B[0;32m    113\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'rb'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 114\u001B[1;33m         \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpil_image\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mBytesIO\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    115\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcolor_mode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'grayscale'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m             \u001B[1;31m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Birds\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3021\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mmessage\u001B[0m \u001B[1;32min\u001B[0m \u001B[0maccept_warnings\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3022\u001B[0m         \u001B[0mwarnings\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwarn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3023\u001B[1;33m     raise UnidentifiedImageError(\n\u001B[0m\u001B[0;32m   3024\u001B[0m         \u001B[1;34m\"cannot identify image file %r\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mfilename\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mfp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3025\u001B[0m     )\n",
      "\u001B[1;31mUnidentifiedImageError\u001B[0m: cannot identify image file <_io.BytesIO object at 0x00000184E7E2EDB0>"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    " \n",
    "class BoundBox:\n",
    "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "\t\tself.xmin = xmin\n",
    "\t\tself.ymin = ymin\n",
    "\t\tself.xmax = xmax\n",
    "\t\tself.ymax = ymax\n",
    "\t\tself.objness = objness\n",
    "\t\tself.classes = classes\n",
    "\t\tself.label = -1\n",
    "\t\tself.score = -1\n",
    " \n",
    "\tdef get_label(self):\n",
    "\t\tif self.label == -1:\n",
    "\t\t\tself.label = np.argmax(self.classes)\n",
    " \n",
    "\t\treturn self.label\n",
    " \n",
    "\tdef get_score(self):\n",
    "\t\tif self.score == -1:\n",
    "\t\t\tself.score = self.classes[self.get_label()]\n",
    " \n",
    "\t\treturn self.score\n",
    " \n",
    "def _sigmoid(x):\n",
    "\treturn 1. / (1. + np.exp(-x))\n",
    " \n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "\tgrid_h, grid_w = netout.shape[:2]\n",
    "\tnb_box = 3\n",
    "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "\tnb_class = netout.shape[-1] - 5\n",
    "\tboxes = []\n",
    "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    " \n",
    "\tfor i in range(grid_h*grid_w):\n",
    "\t\trow = i / grid_w\n",
    "\t\tcol = i % grid_w\n",
    "\t\tfor b in range(nb_box):\n",
    "\t\t\t# 4th element is objectness score\n",
    "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
    "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
    "\t\t\t# first 4 elements are x, y, w, and h\n",
    "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
    "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
    "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "\t\t\t# last elements are class probabilities\n",
    "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
    "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "\t\t\tboxes.append(box)\n",
    "\treturn boxes\n",
    " \n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "\tnew_w, new_h = net_w, net_h\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    " \n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "\tx1, x2 = interval_a\n",
    "\tx3, x4 = interval_b\n",
    "\tif x3 < x1:\n",
    "\t\tif x4 < x1:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x1\n",
    "\telse:\n",
    "\t\tif x2 < x3:\n",
    "\t\t\t return 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x3\n",
    " \n",
    "def bbox_iou(box1, box2):\n",
    "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\tintersect = intersect_w * intersect_h\n",
    "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\tunion = w1*h1 + w2*h2 - intersect\n",
    "\treturn float(intersect) / union\n",
    " \n",
    "def do_nms(boxes, nms_thresh):\n",
    "\tif len(boxes) > 0:\n",
    "\t\tnb_class = len(boxes[0].classes)\n",
    "\telse:\n",
    "\t\treturn\n",
    "\tfor c in range(nb_class):\n",
    "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\t\tfor i in range(len(sorted_indices)):\n",
    "\t\t\tindex_i = sorted_indices[i]\n",
    "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
    "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
    "\t\t\t\tindex_j = sorted_indices[j]\n",
    "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
    " \n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "\t# load the image to get its shape\n",
    "\timage = load_img(filename)\n",
    "\twidth, height = image.size\n",
    "\t# load the image with the required size\n",
    "\timage = load_img(filename, target_size=shape)\n",
    "\t# convert to numpy array\n",
    "\timage = img_to_array(image)\n",
    "\t# scale pixel values to [0, 1]\n",
    "\timage = image.astype('float32')\n",
    "\timage /= 255.0\n",
    "\t# add a dimension so that we have one sample\n",
    "\timage = expand_dims(image, 0)\n",
    "\treturn image, width, height\n",
    " \n",
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
    "\t# enumerate all boxes\n",
    "\tfor box in boxes:\n",
    "\t\t# enumerate all possible labels\n",
    "\t\tfor i in range(len(labels)):\n",
    "\t\t\t# check if the threshold for this label is high enough\n",
    "\t\t\tif box.classes[i] > thresh:\n",
    "\t\t\t\tv_boxes.append(box)\n",
    "\t\t\t\tv_labels.append(labels[i])\n",
    "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
    "\t\t\t\t# don't break, many labels may trigger for one box\n",
    "\treturn v_boxes, v_labels, v_scores\n",
    " \n",
    "# draw all results\n",
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "\t# load the image\n",
    "\tdata = pyplot.imread(filename)\n",
    "\t# plot the image\n",
    "\tpyplot.imshow(data)\n",
    "\t# get the context for drawing boxes\n",
    "\tax = pyplot.gca()\n",
    "\t# plot each box\n",
    "\tfor i in range(len(v_boxes)):\n",
    "\t\tbox = v_boxes[i]\n",
    "\t\t# get coordinates\n",
    "\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "\t\t# calculate width and height of the box\n",
    "\t\twidth, height = x2 - x1, y2 - y1\n",
    "\t\t# create the shape\n",
    "\t\trect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "\t\t# draw the box\n",
    "\t\tax.add_patch(rect)\n",
    "\t\t# draw text and score in top left corner\n",
    "\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "\t\tpyplot.text(x1, y1, label, color='red')\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    " \n",
    "# load yolov3 model\n",
    "model = load_model('../models/yoloV3.h5')\n",
    "# define the expected input shape for the model\n",
    "input_w, input_h = 416, 416\n",
    "# define our new photo\n",
    "photo_filename = '../data/Appelvink_Man/Appelvink_Man_0.mp4'\n",
    "# load and prepare image\n",
    "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
    "# make prediction\n",
    "yhat = model.predict(image)\n",
    "# summarize the shape of the list of arrays\n",
    "print([a.shape for a in yhat])\n",
    "# define the anchors\n",
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "# define the probability threshold for detected objects\n",
    "class_threshold = 0.6\n",
    "boxes = list()\n",
    "for i in range(len(yhat)):\n",
    "\t# decode the output of the network\n",
    "\tboxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
    "# correct the sizes of the bounding boxes for the shape of the image\n",
    "correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "# suppress non-maximal boxes\n",
    "do_nms(boxes, 0.5)\n",
    "# define the labels\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "\t\"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "\t\"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "\t\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "\t\"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "\t\"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "\t\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "\t\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "\t\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "\t\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "# get the details of the detected objects\n",
    "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "# summarize what we found\n",
    "for i in range(len(v_boxes)):\n",
    "\tprint(v_labels[i], v_scores[i])\n",
    "# draw what we found\n",
    "draw_boxes(photo_filename, v_boxes, v_labels, v_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358720ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Birds)",
   "language": "python",
   "name": "pycharm-2edd25c0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}