{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a85f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "from scipy import stats as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ef0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd0aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(31, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f3459a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"../models/weight.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38fe3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cc830ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 31)                3999      \n",
      "=================================================================\n",
      "Total params: 26,384,159\n",
      "Trainable params: 26,384,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c905e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "vid = []\n",
    "label = []\n",
    "for folder in os.listdir('../test'):\n",
    "    for file in os.listdir('../test/' + folder):\n",
    "        label.append(folder)\n",
    "        vid.append(file)\n",
    "df['video'] = vid\n",
    "df['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdbaf2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos = df['video']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "383f59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the tags\n",
    "train = pd.read_csv('../train_new.csv')\n",
    "y = train['class']\n",
    "y = pd.get_dummies(y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab4dd59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:38<00:00, 19.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# creating two lists to store predicted and actual tags\n",
    "\n",
    "\n",
    "\n",
    "# for loop to extract frames from each test video\n",
    "for i in tqdm(range(test_videos.shape[0])):\n",
    "    count = 0\n",
    "    videoFile = test_videos[i]\n",
    "    cap = cv2.VideoCapture('../test/'+df['label'][i]+\"/\"+videoFile)   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if (frameId % math.floor(frameRate) == 0):\n",
    "            # storing the frames of this particular video in temp folder\n",
    "            filename ='../temp/' + \"_frame%d.jpg\" % count;count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2908ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_images = []\n",
    "actual = []\n",
    "for folder in os.listdir('../temp'):\n",
    "    actual.append('Groenling')\n",
    "    img = image.load_img('../temp/' + folder, target_size=(224,224,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    prediction_images.append(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4e836555",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []       \n",
    "    # converting all the frames for a test video into numpy array\n",
    "prediction_images = np.array(prediction_images)\n",
    "prediction_images2 = np.array(prediction_images)\n",
    "    # extracting features using pre-trained model\n",
    "prediction_images = base_model.predict(prediction_images)\n",
    "\n",
    "#     # converting features in one dimensional array\n",
    "# prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
    "#     # predicting tags for each array\n",
    "# prediction = model.predict(prediction_images)\n",
    "#     # appending the mode of predictions in predict list to assign the tag to the video\n",
    "# predict.append(y.columns.values[s.mode(prediction)[0][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c4346c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4a5d2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(prediction_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6685b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_x=np.argmax(prediction,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c716fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for name in os.listdir('../training'):\n",
    "    l.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "919c3575",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in classes_x:\n",
    "    predict.append(l[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "898c7d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22075055187637968"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f668e62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf1137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601aac49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Birds)",
   "language": "python",
   "name": "pycharm-2edd25c0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
